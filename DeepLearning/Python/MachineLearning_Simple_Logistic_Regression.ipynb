{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gothic-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([2,4,6,8,10,12,14,16,18,20]).reshape(10,1)\n",
    "t_data = np.array([0,0,0,0,0,0,1,1,1,1]).reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "international-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.73766259]] , W,shape = (1, 1) , b = [0.1948421] , b.shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W =\", W, \", W,shape =\", W.shape, \", b =\", b, \", b.shape =\", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clinical-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7     # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum( t*np.log(y + delta) + (1-t) * np.log((1 - y) + delta) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "balanced-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분 함수\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.000\n",
    "    grad = np.zeros_like(x) # x 크기의 어레이 선언 및 초기화\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx] # x 바뀌기 때문에 저장해둠\n",
    "        x[idx]= float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uniform-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    delta = 1e-7      # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "     # cross-entropy\n",
    "    return -np.sum( t*np.log(y + delta) + (1-t) * np.log((1 - y) + delta) )\n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y  > 0.5:\n",
    "        result = 1     # True\n",
    "    else :\n",
    "        result = 0     # False\n",
    "        \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pressing-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value = 32.377090499139406 Initial W = [[0.73766259]] \n",
      " , b= [0.1948421]\n",
      "step = 0 error value 15.274598988436253 W = [[0.3234422]] , b= [0.14198734]\n",
      "step = 400 error value 2.9106618162237328 W = [[0.43221359]] , b= [-4.25410853]\n",
      "step = 800 error value 1.7614092756492976 W = [[0.45906752]] , b= [-5.71713111]\n",
      "step = 1200 error value 1.5050244590416364 W = [[0.53505266]] , b= [-6.72872379]\n",
      "step = 1600 error value 1.3437218130159139 W = [[0.595542]] , b= [-7.53185083]\n",
      "step = 2000 error value 1.2295428418690257 W = [[0.64655731]] , b= [-8.20772921]\n",
      "step = 2400 error value 1.1427970869805963 W = [[0.69110388]] , b= [-8.79687152]\n",
      "step = 2800 error value 1.073713590230537 W = [[0.73091415]] , b= [-9.32261099]\n",
      "step = 3200 error value 1.0168158242978982 W = [[0.76708517]] , b= [-9.79970688]\n",
      "step = 3600 error value 0.9687608155033726 W = [[0.80035919]] , b= [-10.2381342]\n",
      "step = 4000 error value 0.9273746380705581 W = [[0.83126384]] , b= [-10.64497566]\n",
      "step = 4400 error value 0.8911727911750015 W = [[0.86018881]] , b= [-11.02545654]\n",
      "step = 4800 error value 0.8591013414692621 W = [[0.8874308]] , b= [-11.38355132]\n",
      "step = 5200 error value 0.8303879232278687 W = [[0.91322142]] , b= [-11.72235952]\n",
      "step = 5600 error value 0.8044513914134849 W = [[0.93774529]] , b= [-12.04434908]\n",
      "step = 6000 error value 0.7808446331790679 W = [[0.9611521]] , b= [-12.35151989]\n",
      "step = 6400 error value 0.7592170365936572 W = [[0.98356513]] , b= [-12.64551713]\n",
      "step = 6800 error value 0.7392890893609312 W = [[1.00508719]] , b= [-12.92771202]\n",
      "step = 7200 error value 0.7208347239751146 W = [[1.02580501]] , b= [-13.1992605]\n",
      "step = 7600 error value 0.7036687591286799 W = [[1.04579252]] , b= [-13.46114695]\n",
      "step = 8000 error value 0.6876377821683384 W = [[1.06511327]] , b= [-13.71421718]\n",
      "step = 8400 error value 0.672613408904821 W = [[1.08382234]] , b= [-13.95920377]\n",
      "step = 8800 error value 0.6584872197367778 W = [[1.1019678]] , b= [-14.19674588]\n",
      "step = 9200 error value 0.6451668995492592 W = [[1.1195919]] , b= [-14.42740476]\n",
      "step = 9600 error value 0.632573256381089 W = [[1.13673198]] , b= [-14.65167623]\n",
      "step = 10000 error value 0.6206378912198364 W = [[1.15342123]] , b= [-14.87000065]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2 # 발산하는 경우 1e-3 ~ 1e-6 등으로 바꿔 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data) # f(x) = loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value =\", error_val(x_data, t_data), \"Initial W =\", W, \"\\n\", \", b=\", b)\n",
    "\n",
    "for step in range(10001):\n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step =\", step, \"error value\", error_val(x_data, t_data), \"W =\", W, \", b=\", b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "american-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10868807e-05]] 0\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(3)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conscious-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99132124]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(17)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-electron",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
